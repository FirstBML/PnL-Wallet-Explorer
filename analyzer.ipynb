{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d5ef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Moralis API connection successful!\n",
      "\n",
      "üîç Testing 5 known active wallets...\n",
      "\n",
      "--- Wallet 1/3 ---\n",
      "\n",
      "Analyzing wallet: 0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\n",
      "  Checking eth...\n",
      "    eth: 50 native, 50 ERC20\n",
      "  Checking bsc...\n",
      "    bsc: 50 native, 50 ERC20\n",
      "  Checking polygon...\n",
      "    polygon: 50 native, 50 ERC20\n",
      "  Checking arbitrum...\n",
      "    arbitrum: 50 native, 50 ERC20\n",
      "  Checking optimism...\n",
      "    optimism: 50 native, 50 ERC20\n",
      "  Checking base...\n",
      "    base: 50 native, 50 ERC20\n",
      "  ‚úÖ QUALIFIED: 600 total activities, 6 chains\n",
      "\n",
      "--- Wallet 2/3 ---\n",
      "\n",
      "Analyzing wallet: 0x28C6c06298d514Db089934071355E5743bf21d60\n",
      "  Checking eth...\n",
      "    eth: 50 native, 50 ERC20\n",
      "  Checking bsc...\n",
      "    bsc: 50 native, 50 ERC20\n",
      "  Checking polygon...\n",
      "    polygon: 17 native, 50 ERC20\n",
      "  Checking arbitrum...\n",
      "    arbitrum: 13 native, 50 ERC20\n",
      "  Checking optimism...\n",
      "    optimism: 4 native, 50 ERC20\n",
      "  Checking base...\n",
      "    base: 50 native, 50 ERC20\n",
      "  ‚úÖ QUALIFIED: 484 total activities, 6 chains\n",
      "\n",
      "--- Wallet 3/3 ---\n",
      "\n",
      "Analyzing wallet: 0xF977814e90dA44bFA03b6295A0616a897441aceC\n",
      "  Checking eth...\n",
      "    eth: 50 native, 50 ERC20\n",
      "  Checking bsc...\n",
      "    bsc: 50 native, 50 ERC20\n",
      "  Checking polygon...\n",
      "    polygon: 50 native, 50 ERC20\n",
      "  Checking arbitrum...\n",
      "    arbitrum: 50 native, 50 ERC20\n",
      "  Checking optimism...\n",
      "    optimism: 50 native, 50 ERC20\n",
      "  Checking base...\n",
      "    base: 50 native, 50 ERC20\n",
      "  ‚úÖ QUALIFIED: 600 total activities, 6 chains\n",
      "\n",
      "‚úÖ 3 wallets qualified!\n",
      "\n",
      "üìä Getting detailed transaction data...\n",
      "\n",
      "  Processing 0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045...\n",
      "    Getting eth data...\n",
      "    Getting bsc data...\n",
      "    Getting polygon data...\n",
      "    Getting arbitrum data...\n",
      "    Getting optimism data...\n",
      "    Getting base data...\n",
      "\n",
      "  Processing 0x28C6c06298d514Db089934071355E5743bf21d60...\n",
      "    Getting eth data...\n",
      "    Getting bsc data...\n",
      "    Getting polygon data...\n",
      "    Getting arbitrum data...\n",
      "    Getting optimism data...\n",
      "    Getting base data...\n",
      "\n",
      "  Processing 0xF977814e90dA44bFA03b6295A0616a897441aceC...\n",
      "    Getting eth data...\n",
      "    Getting bsc data...\n",
      "    Getting polygon data...\n",
      "    Getting arbitrum data...\n",
      "    Getting optimism data...\n",
      "    Getting base data...\n",
      "\n",
      "üéâ SUCCESS! Collected 1684 transactions\n",
      "üíæ Data saved to 'moralis_wallet_data.csv'\n",
      "\n",
      "Sample data:\n",
      "                                             tx_hash  \\\n",
      "0  0x6645bf8a80fb3b08aaf3fc30418ae51f26014a8e12bd...   \n",
      "1  0x6c1ca6ef4485dacb1342109ee84b9bfce0e16e519719...   \n",
      "2  0x0b2e99577678600fd37eb5f094d17c8dbc55de67f807...   \n",
      "3  0xdd82db1016b9834f3c8094a9eb4c0e879f0ef37bcc2e...   \n",
      "4  0x6b9a4e2e3213f7124241b574fd44382418d31d2b8a3c...   \n",
      "\n",
      "                                       wallet blockchain           action  \\\n",
      "0  0x28C6c06298d514Db089934071355E5743bf21d60    polygon  native_transfer   \n",
      "1  0x28C6c06298d514Db089934071355E5743bf21d60    polygon  native_transfer   \n",
      "2  0x28C6c06298d514Db089934071355E5743bf21d60    polygon  native_transfer   \n",
      "3  0x28C6c06298d514Db089934071355E5743bf21d60    polygon  native_transfer   \n",
      "4  0x28C6c06298d514Db089934071355E5743bf21d60    polygon  native_transfer   \n",
      "\n",
      "  transaction_type  \n",
      "0          deposit  \n",
      "1          deposit  \n",
      "2          deposit  \n",
      "3          deposit  \n",
      "4          deposit  \n",
      "\n",
      "üìà Final Results Summary:\n",
      "Total transactions: 1684\n",
      "Unique wallets: 3\n",
      "Blockchains: 6\n",
      "Date range: 2021-07-29 00:19:06+00:00 to 2025-09-03 06:50:11+00:00\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJub25jZSI6IjdlMjBjNDk0LWU0MjAtNGFmOC05MzM2LTkxNTBjNDU3MmJjZCIsIm9yZ0lkIjoiNDY4ODE1IiwidXNlcklkIjoiNDgyMjkyIiwidHlwZUlkIjoiMDk3MTE4YTItNWVkOC00Yjc2LTg5YWItMjM5NDgzNDVjYzNiIiwidHlwZSI6IlBST0pFQ1QiLCJpYXQiOjE3NTY4NDM1NjIsImV4cCI6NDkxMjYwMzU2Mn0.yLn2ojeo6b4qJA9IYnSJlel5gZVlJChuZbhqkUBSLeo\"\n",
    "\n",
    "class FixedMoralisAnalyzer:\n",
    "    def __init__(self, api_key: str, cache_file: str = \"moralis_cache.json\"):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://deep-index.moralis.io/api/v2\"\n",
    "        self.headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"X-API-Key\": api_key\n",
    "        }\n",
    "        self.chains = {\n",
    "            'eth': '0x1',\n",
    "            'bsc': '0x38', \n",
    "            'polygon': '0x89',\n",
    "            'arbitrum': '0xa4b1',\n",
    "            'optimism': '0xa',\n",
    "            'base': '0x2105'\n",
    "        }\n",
    "\n",
    "        # Initialize cache\n",
    "        self.cache_file = cache_file\n",
    "        if os.path.exists(cache_file):\n",
    "            with open(cache_file, \"r\") as f:\n",
    "                try:\n",
    "                    self.cache = json.load(f)\n",
    "                except:\n",
    "                    self.cache = {}\n",
    "        else:\n",
    "            self.cache = {}\n",
    "\n",
    "    def _make_request(self, endpoint: str, params: dict) -> dict:\n",
    "        \"\"\"Helper with caching logic\"\"\"\n",
    "        key = hashlib.sha256((endpoint + json.dumps(params, sort_keys=True)).encode()).hexdigest()\n",
    "\n",
    "        if key in self.cache:\n",
    "            # ‚úÖ Cached response\n",
    "            return self.cache[key]\n",
    "\n",
    "        # ‚ùå Not cached ‚Üí API call\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        response = requests.get(url, headers=self.headers, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Save to cache\n",
    "            self.cache[key] = data\n",
    "            with open(self.cache_file, \"w\") as f:\n",
    "                json.dump(self.cache, f)\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"API Error {response.status_code}: {response.text[:200]}\")\n",
    "            return {}\n",
    "\n",
    "\n",
    "        \n",
    "    def test_connection(self) -> bool:\n",
    "        \"\"\"Test if API key works with native balance endpoint\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.base_url}/0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045/balance\"\n",
    "            params = {\"chain\": \"0x1\"}  # Use hex chain ID\n",
    "            \n",
    "            response = requests.get(url, headers=self.headers, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                print(\"‚úÖ Moralis API connection successful!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ùå API Error: {response.status_code}\")\n",
    "                print(f\"Response: {response.text}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Connection error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_native_transactions(self, wallet: str, chain: str = '0x1', limit: int = 100) -> List[Dict]:\n",
    "        endpoint = f\"/{wallet}\"\n",
    "        params = {\"chain\": chain, \"limit\": limit}\n",
    "        data = self._make_request(endpoint, params)\n",
    "        return data.get('result', [])\n",
    "\n",
    "    def get_erc20_transfers(self, wallet: str, chain: str = '0x1', limit: int = 100) -> List[Dict]:\n",
    "        endpoint = f\"/{wallet}/erc20/transfers\"\n",
    "        params = {\"chain\": chain, \"limit\": limit}\n",
    "        data = self._make_request(endpoint, params)\n",
    "        return data.get('result', [])\n",
    "\n",
    "    def analyze_single_wallet(self, wallet: str) -> Optional[Dict]:\n",
    "        \"\"\"Analyze a single wallet across all chains\"\"\"\n",
    "        print(f\"\\nAnalyzing wallet: {wallet}\")\n",
    "        \n",
    "        wallet_stats = {\n",
    "            'wallet': wallet,\n",
    "            'total_native_txs': 0,\n",
    "            'total_erc20_transfers': 0,\n",
    "            'active_chains': 0,\n",
    "            'chain_details': {}\n",
    "        }\n",
    "        \n",
    "        for chain_name, chain_id in self.chains.items():\n",
    "            print(f\"  Checking {chain_name}...\")\n",
    "            \n",
    "            try:\n",
    "                # Get native transactions\n",
    "                native_txs = self.get_native_transactions(wallet, chain_id, limit=50)\n",
    "                \n",
    "                # Get ERC20 transfers  \n",
    "                erc20_transfers = self.get_erc20_transfers(wallet, chain_id, limit=50)\n",
    "                \n",
    "                chain_native_count = len(native_txs)\n",
    "                chain_erc20_count = len(erc20_transfers)\n",
    "                \n",
    "                if chain_native_count > 0 or chain_erc20_count > 0:\n",
    "                    wallet_stats['active_chains'] += 1\n",
    "                    wallet_stats['total_native_txs'] += chain_native_count\n",
    "                    wallet_stats['total_erc20_transfers'] += chain_erc20_count\n",
    "                    \n",
    "                    wallet_stats['chain_details'][chain_name] = {\n",
    "                        'native_txs': chain_native_count,\n",
    "                        'erc20_transfers': chain_erc20_count\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"    {chain_name}: {chain_native_count} native, {chain_erc20_count} ERC20\")\n",
    "                \n",
    "                # Rate limiting\n",
    "                time.sleep(0.3)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Error with {chain_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Check qualification criteria (simplified for testing)\n",
    "        total_activity = wallet_stats['total_native_txs'] + wallet_stats['total_erc20_transfers']\n",
    "        \n",
    "        if total_activity >= 10 and wallet_stats['active_chains'] >= 2:\n",
    "            print(f\"  ‚úÖ QUALIFIED: {total_activity} total activities, {wallet_stats['active_chains']} chains\")\n",
    "            return wallet_stats\n",
    "        else:\n",
    "            print(f\"  ‚ùå Not qualified: {total_activity} activities, {wallet_stats['active_chains']} chains\")\n",
    "            return None\n",
    "    \n",
    "    def get_detailed_data_for_wallet(self, wallet: str, max_per_chain: int = 100) -> List[Dict]:\n",
    "        \"\"\"Get detailed transaction data for a qualified wallet\"\"\"\n",
    "        all_transactions = []\n",
    "        \n",
    "        for chain_name, chain_id in self.chains.items():\n",
    "            try:\n",
    "                print(f\"    Getting {chain_name} data...\")\n",
    "                \n",
    "                # Get native transactions\n",
    "                native_txs = self.get_native_transactions(wallet, chain_id, limit=max_per_chain)\n",
    "                \n",
    "                for tx in native_txs:\n",
    "                    processed = {\n",
    "                        'tx_hash': tx.get('hash'),\n",
    "                        'block_time': tx.get('block_timestamp'),\n",
    "                        'wallet': wallet,\n",
    "                        'blockchain': chain_name,\n",
    "                        'from_address': tx.get('from_address'),\n",
    "                        'to_address': tx.get('to_address'),\n",
    "                        'value_wei': tx.get('value', '0'),\n",
    "                        'value_native': float(tx.get('value', '0')) / 1e18 if tx.get('value') else 0,\n",
    "                        'gas_used': tx.get('gas_used'),\n",
    "                        'gas_price': tx.get('gas_price'),\n",
    "                        'action': 'native_transfer',\n",
    "                        'transaction_type': 'deposit' if tx.get('to_address', '').lower() == wallet.lower() else 'withdrawal'\n",
    "                    }\n",
    "                    all_transactions.append(processed)\n",
    "                \n",
    "                # Get ERC20 transfers\n",
    "                erc20_transfers = self.get_erc20_transfers(wallet, chain_id, limit=max_per_chain)\n",
    "                \n",
    "                for transfer in erc20_transfers:\n",
    "                    processed = {\n",
    "                        'tx_hash': transfer.get('transaction_hash'),\n",
    "                        'block_time': transfer.get('block_timestamp'),\n",
    "                        'wallet': wallet,\n",
    "                        'blockchain': chain_name,\n",
    "                        'from_address': transfer.get('from_address'),\n",
    "                        'to_address': transfer.get('to_address'),\n",
    "                        'token_address': transfer.get('address'),\n",
    "                        'token_symbol': transfer.get('token_symbol'),\n",
    "                        'token_name': transfer.get('token_name'),\n",
    "                        'value_raw': transfer.get('value', '0'),\n",
    "                        'decimals': transfer.get('token_decimals', '18'),\n",
    "                        'action': 'erc20_transfer',\n",
    "                        'transaction_type': 'deposit' if transfer.get('to_address', '').lower() == wallet.lower() else 'withdrawal'\n",
    "                    }\n",
    "                    \n",
    "                    # Calculate human-readable amount\n",
    "                    try:\n",
    "                        decimals = int(transfer.get('token_decimals', '18'))\n",
    "                        raw_value = float(transfer.get('value', '0'))\n",
    "                        processed['amount'] = raw_value / (10 ** decimals)\n",
    "                    except:\n",
    "                        processed['amount'] = 0\n",
    "                    \n",
    "                    all_transactions.append(processed)\n",
    "                \n",
    "                time.sleep(0.5)  # Rate limiting\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Error getting {chain_name} details: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return all_transactions\n",
    "\n",
    "def run_fixed_moralis_analysis(api_key: str, max_wallets: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Run the complete analysis with fixed endpoints\"\"\"\n",
    "    \n",
    "    analyzer = FixedMoralisAnalyzer(api_key)\n",
    "    \n",
    "    # Test connection\n",
    "    if not analyzer.test_connection():\n",
    "        print(\"‚ùå Connection failed. Check your API key.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Test wallets (known active addresses)\n",
    "    test_wallets = [\n",
    "        \"0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\",  # Vitalik\n",
    "        \"0x28C6c06298d514Db089934071355E5743bf21d60\",  # Binance\n",
    "        \"0xF977814e90dA44bFA03b6295A0616a897441aceC\",  # Alameda\n",
    "        \"0x3fC91A3afd70395Cd496C647d5a6CC9D4B2b7FAD\",  # Uniswap\n",
    "        \"0x1111111254fb6c44bAC0beD2854e76F90643097d\",  # 1inch\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüîç Testing {len(test_wallets)} known active wallets...\")\n",
    "    \n",
    "    qualified_wallets = []\n",
    "    \n",
    "    for i, wallet in enumerate(test_wallets[:max_wallets], 1):\n",
    "        print(f\"\\n--- Wallet {i}/{max_wallets} ---\")\n",
    "        result = analyzer.analyze_single_wallet(wallet)\n",
    "        \n",
    "        if result:\n",
    "            qualified_wallets.append(result)\n",
    "        \n",
    "        # Rate limiting between wallets\n",
    "        if i < len(test_wallets):\n",
    "            time.sleep(2)\n",
    "    \n",
    "    if not qualified_wallets:\n",
    "        print(\"\\n‚ùå No wallets qualified\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"\\n‚úÖ {len(qualified_wallets)} wallets qualified!\")\n",
    "    print(\"\\nüìä Getting detailed transaction data...\")\n",
    "    \n",
    "    # Get detailed data\n",
    "    all_detailed_data = []\n",
    "    \n",
    "    for wallet_info in qualified_wallets:\n",
    "        wallet = wallet_info['wallet']\n",
    "        print(f\"\\n  Processing {wallet}...\")\n",
    "        \n",
    "        wallet_transactions = analyzer.get_detailed_data_for_wallet(wallet, max_per_chain=50)\n",
    "        all_detailed_data.extend(wallet_transactions)\n",
    "        \n",
    "        time.sleep(1)  # Rate limiting between wallets\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if all_detailed_data:\n",
    "        df = pd.DataFrame(all_detailed_data)\n",
    "        df['block_time'] = pd.to_datetime(df['block_time'])\n",
    "        df = df.sort_values('block_time').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nüéâ SUCCESS! Collected {len(df)} transactions\")\n",
    "        \n",
    "        # Save results\n",
    "        df.to_csv('moralis_wallet_data.csv', index=False)\n",
    "        print(\"üíæ Data saved to 'moralis_wallet_data.csv'\")\n",
    "        \n",
    "        # Show sample\n",
    "        print(f\"\\nSample data:\")\n",
    "        print(df[['tx_hash', 'wallet', 'blockchain', 'action', 'transaction_type']].head())\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"‚ùå No transaction data collected\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# USAGE:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual Moralis API key\n",
    "\n",
    "\n",
    "    if API_KEY == \"MORALIS_API_KEY\":\n",
    "        print(\"‚ö†Ô∏è  Please set your actual Moralis API key\")\n",
    "    else:\n",
    "        result = run_fixed_moralis_analysis(API_KEY, max_wallets=3)\n",
    "        \n",
    "        if not result.empty:\n",
    "            print(f\"\\nüìà Final Results Summary:\")\n",
    "            print(f\"Total transactions: {len(result)}\")\n",
    "            print(f\"Unique wallets: {result['wallet'].nunique()}\")\n",
    "            print(f\"Blockchains: {result['blockchain'].nunique()}\")\n",
    "            print(f\"Date range: {result['block_time'].min()} to {result['block_time'].max()}\")\n",
    "        else:\n",
    "            print(\"No data collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae7d7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -------------------------------\n",
    "# Load environment variables\n",
    "# -------------------------------\n",
    "load_dotenv()\n",
    "MORALIS_API_KEY = os.getenv(\"MORALIS_API_KEY\")\n",
    "COINGECKO_API_KEY = os.getenv(\"GECKO_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325d735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ERC20 transfers on eth...\n",
      "Fetching ERC20 transfers on bsc...\n",
      "Fetching ERC20 transfers on polygon...\n",
      "Fetching ERC20 transfers on arbitrum...\n",
      "Fetching ERC20 transfers on optimism...\n",
      "Fetching ERC20 transfers on base...\n",
      "                                        wallet blockchain  \\\n",
      "0   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "1   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "2   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "3   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "4   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "5   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "6   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "7   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "8   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "9   0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "10  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "11  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "12  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "13  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045    polygon   \n",
      "14  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045   optimism   \n",
      "15  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045   optimism   \n",
      "16  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045   optimism   \n",
      "17  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045   optimism   \n",
      "18  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045   optimism   \n",
      "19  0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045   optimism   \n",
      "\n",
      "                                              tx_hash  \\\n",
      "0   0x1b1792a6ea6c0ca4f4440181b6a4a1cbbff085043066...   \n",
      "1   0xfbc546350589442458fa38ec85aa63d8d26348e9ff04...   \n",
      "2   0x6d893b80bb008160897c59ae2dc0e5c224e0e91d2fc4...   \n",
      "3   0x29ec470327f66f070c0f971b605f84118c3801ba3ae4...   \n",
      "4   0x880ddadd55025c622a3ee29d94c9c873f46546b8f65f...   \n",
      "5   0x97352ab4afaa4a72a07d5cce4cf25b2946c2d46b4ca7...   \n",
      "6   0xec2443415286e11885622393948ddbb2921e3f63ae4f...   \n",
      "7   0x85dea7155d6bb7f0daf1fc0bfbf0b4c1206ad0942501...   \n",
      "8   0xbad5e36d7d7d609b3925ba9741bb863c280c187f9106...   \n",
      "9   0x98d14773fa1952635e95094a76175ce9b7087a6b6eb3...   \n",
      "10  0x183ed01a041e0fcd9a910dada05f641492dc7610ece0...   \n",
      "11  0xef3de95d326cb14e4a2b9be727b44b46eb1c57d7f962...   \n",
      "12  0x5b3e5f6137c5d1e286a43e22c6cb15389ca5d0ab78a4...   \n",
      "13  0xaa4a674d9c73772641559b70d3a6f026c9db44a822c1...   \n",
      "14  0xdb23645a38e78ac50edb5aa210c76a3eb08f11bf914c...   \n",
      "15  0xf6951d2ebb9b958140b30d2bb9c003bcefa2b80459e7...   \n",
      "16  0x0141ef931c12ba382731c137555e6ce42ad6f047fc8b...   \n",
      "17  0x32b520b4568a48db356d02ba39e6780977b83a7dc2ef...   \n",
      "18  0x06db663e0d6aefe087c2d86372fc590b49894a697b88...   \n",
      "19  0x4e7a1a73d43f4bd83421631978ce1906d4d3bab37708...   \n",
      "\n",
      "                  block_time  \\\n",
      "0  2025-06-09 02:23:00+00:00   \n",
      "1  2025-06-09 06:14:45+00:00   \n",
      "2  2025-06-09 06:14:55+00:00   \n",
      "3  2025-06-09 06:15:03+00:00   \n",
      "4  2025-06-09 06:15:11+00:00   \n",
      "5  2025-06-12 19:42:01+00:00   \n",
      "6  2025-06-15 14:24:09+00:00   \n",
      "7  2025-06-16 18:10:02+00:00   \n",
      "8  2025-06-22 06:38:30+00:00   \n",
      "9  2025-06-23 12:11:33+00:00   \n",
      "10 2025-06-24 02:41:47+00:00   \n",
      "11 2025-07-06 19:24:09+00:00   \n",
      "12 2025-07-08 15:54:33+00:00   \n",
      "13 2025-07-08 18:52:47+00:00   \n",
      "14 2025-07-15 18:02:41+00:00   \n",
      "15 2025-07-15 18:02:43+00:00   \n",
      "16 2025-07-15 18:02:45+00:00   \n",
      "17 2025-07-15 18:02:51+00:00   \n",
      "18 2025-07-15 18:02:53+00:00   \n",
      "19 2025-07-15 18:06:53+00:00   \n",
      "\n",
      "                                         token_symbol  \\\n",
      "0                                 bigbossgarments.com   \n",
      "1   Please visit bigbossgarments.com | &#x2705; VE...   \n",
      "2   Please visit bigbossgarments.com | &#x2705; VE...   \n",
      "3   Please visit bigbossgarments.com | &#x2705; VE...   \n",
      "4   Please visit bigbossgarments.com | &#x2705; VE...   \n",
      "5                                                USDC   \n",
      "6                                                SWOL   \n",
      "7                                                 BSC   \n",
      "8                                               UERII   \n",
      "9                                                 DAI   \n",
      "10                                                 P3   \n",
      "11                                               SWOL   \n",
      "12  $BASE Visit WWW.BASETERMINAL.SHOP to claim reward   \n",
      "13  $BASE Visit WWW.BASETERMINAL.SHOP to claim reward   \n",
      "14                                                 TT   \n",
      "15                                                 TT   \n",
      "16                                                 TT   \n",
      "17                                                 TT   \n",
      "18                                                 TT   \n",
      "19                                                 TT   \n",
      "\n",
      "                                 token_address        amount  price_usd  \\\n",
      "0   0xa429d00f5b3d304d9eb2a6c0ccc7d7232364d59b   10000.00000        0.0   \n",
      "1   0x5c2942a493dc53cd89ba656c3da1180ffcc59dab  100000.00000        0.0   \n",
      "2   0x5c2942a493dc53cd89ba656c3da1180ffcc59dab  100000.00000        0.0   \n",
      "3   0x5c2942a493dc53cd89ba656c3da1180ffcc59dab  100000.00000        0.0   \n",
      "4   0x5c2942a493dc53cd89ba656c3da1180ffcc59dab  100000.00000        0.0   \n",
      "5   0x3c499c542cef5e3811e1192ce70d8cc03d5c3359       0.18518        0.0   \n",
      "6   0xa1ca6299ba48366af1845a9a8ae59b87ff0d5c01     150.00000        0.0   \n",
      "7   0x8701b4c17fce6128c7b95904f7ca79abfe813ce6      10.00000        0.0   \n",
      "8   0xd566c529b33ecf15170f600d4b1ab12468c8efc6    5000.00000        0.0   \n",
      "9   0x8f3cf7ad23cd3cadbd9735aff958023239c6a063       0.01000        0.0   \n",
      "10  0xbef18f56a7c848d530af1e97b033980cd6cb4a76       3.73571        0.0   \n",
      "11  0xa1ca6299ba48366af1845a9a8ae59b87ff0d5c01     200.00000        0.0   \n",
      "12  0x489e93e7e2d90a8e3552d6862d757b1088803094   18506.77000        0.0   \n",
      "13  0x803bdb1d11c5ca39054a9591d849bcbec055378c  120000.00000        0.0   \n",
      "14  0x91cd2a4a8c7c5ed4661148ce795cd12b1687a810      10.00000        0.0   \n",
      "15  0x91cd2a4a8c7c5ed4661148ce795cd12b1687a810      10.00000        0.0   \n",
      "16  0x91cd2a4a8c7c5ed4661148ce795cd12b1687a810      10.00000        0.0   \n",
      "17  0x91cd2a4a8c7c5ed4661148ce795cd12b1687a810      10.00000        0.0   \n",
      "18  0x91cd2a4a8c7c5ed4661148ce795cd12b1687a810      10.00000        0.0   \n",
      "19  0x91cd2a4a8c7c5ed4661148ce795cd12b1687a810      10.00000        0.0   \n",
      "\n",
      "    usd_value transaction_type  \n",
      "0         0.0          deposit  \n",
      "1         0.0          deposit  \n",
      "2         0.0          deposit  \n",
      "3         0.0          deposit  \n",
      "4         0.0          deposit  \n",
      "5         0.0          deposit  \n",
      "6         0.0          deposit  \n",
      "7         0.0          deposit  \n",
      "8         0.0          deposit  \n",
      "9         0.0          deposit  \n",
      "10        0.0          deposit  \n",
      "11        0.0          deposit  \n",
      "12        0.0          deposit  \n",
      "13        0.0          deposit  \n",
      "14        0.0          deposit  \n",
      "15        0.0          deposit  \n",
      "16        0.0          deposit  \n",
      "17        0.0          deposit  \n",
      "18        0.0          deposit  \n",
      "19        0.0          deposit  \n",
      "\n",
      "Summary USD values:\n",
      "transaction_type\n",
      "deposit       0.116087\n",
      "withdrawal    0.000000\n",
      "Name: usd_value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -------------------------------\n",
    "# Cache for prices\n",
    "# -------------------------------\n",
    "class PriceCache:\n",
    "    def __init__(self, filename=\"price_cache.json\"):\n",
    "        self.filename = filename\n",
    "        self.cache = {}\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, \"r\") as f:\n",
    "                try:\n",
    "                    self.cache = json.load(f)\n",
    "                except:\n",
    "                    self.cache = {}\n",
    "\n",
    "    def get(self, key: str):\n",
    "        return self.cache.get(key)\n",
    "\n",
    "    def set(self, key: str, value):\n",
    "        self.cache[key] = value\n",
    "        with open(self.filename, \"w\") as f:\n",
    "            json.dump(self.cache, f)\n",
    "\n",
    "# -------------------------------\n",
    "# Cache for contract-to-CGID mapping\n",
    "# -------------------------------\n",
    "class AddressCache:\n",
    "    def __init__(self, filename=\"address_to_cgid.json\"):\n",
    "        self.filename = filename\n",
    "        self.cache = {}\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, \"r\") as f:\n",
    "                try:\n",
    "                    self.cache = json.load(f)\n",
    "                except:\n",
    "                    self.cache = {}\n",
    "\n",
    "    def get(self, key: str):\n",
    "        return self.cache.get(key)\n",
    "\n",
    "    def set(self, key: str, value):\n",
    "        self.cache[key] = value\n",
    "        with open(self.filename, \"w\") as f:\n",
    "            json.dump(self.cache, f)\n",
    "\n",
    "# -------------------------------\n",
    "# Extended Analyzer\n",
    "# -------------------------------\n",
    "# -------------------------------\n",
    "# Extended Analyzer\n",
    "# -------------------------------\n",
    "class ExtendedMoralisAnalyzer:\n",
    "    def __init__(self, api_key: str, use_cache: bool = True, force_refresh: bool = False):\n",
    "        \"\"\"\n",
    "        :param api_key: Moralis API key\n",
    "        :param use_cache: if True, prefer cache\n",
    "        :param force_refresh: if True, ignore cache and refresh from API\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://deep-index.moralis.io/api/v2\"\n",
    "        self.headers = {\"Accept\": \"application/json\", \"X-API-Key\": api_key}\n",
    "        self.use_cache = use_cache\n",
    "        self.force_refresh = force_refresh\n",
    "\n",
    "        self.chains = {\n",
    "            'eth': '0x1',\n",
    "            'bsc': '0x38',\n",
    "            'polygon': '0x89',\n",
    "            'arbitrum': '0xa4b1',\n",
    "            'optimism': '0xa',\n",
    "            'base': '0x2105'\n",
    "        }\n",
    "\n",
    "        self.price_cache = PriceCache()\n",
    "        self.address_cache = AddressCache()\n",
    "        self.moralis_cache = ExtendedMoralisAnalyzer()\n",
    "\n",
    "    # -------------------------------\n",
    "    # Fetch ERC20 Transfers (cached)\n",
    "    # -------------------------------\n",
    "    def get_erc20_transfers(self, wallet: str, chain: str, limit: int = 50) -> List[Dict]:\n",
    "        cache_key = f\"{wallet}_{chain}\"\n",
    "        cached = self.moralis_cache.get(wallet, chain)\n",
    "\n",
    "        if self.use_cache and cached and not self.force_refresh:\n",
    "            return cached\n",
    "\n",
    "        try:\n",
    "            url = f\"{self.base_url}/{wallet}/erc20/transfers\"\n",
    "            params = {\"chain\": chain, \"limit\": limit}\n",
    "            response = requests.get(url, headers=self.headers, params=params)\n",
    "            if response.status_code == 200:\n",
    "                result = response.json().get('result', [])\n",
    "                if self.use_cache:\n",
    "                    self.moralis_cache.set(wallet, chain, result)\n",
    "                return result\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"ERC20 transfer error: {e}\")\n",
    "            return []\n",
    "\n",
    "    # -------------------------------\n",
    "    # Price Fetcher (cached)\n",
    "    # -------------------------------\n",
    "    def get_price_usd(self, symbol: str, timestamp: str, token_address: str = None, blockchain: str = \"ethereum\") -> Optional[float]:\n",
    "        if not symbol and not token_address:\n",
    "            return None\n",
    "\n",
    "        symbol = (symbol or \"\").lower()\n",
    "        date_str = timestamp.split(\"T\")[0]\n",
    "        cache_key = f\"{symbol}_{token_address}_{date_str}\"\n",
    "        cached = self.price_cache.get(cache_key)\n",
    "\n",
    "        if self.use_cache and cached and not self.force_refresh:\n",
    "            return cached\n",
    "\n",
    "        try:\n",
    "            mapping = {\n",
    "                \"eth\": \"ethereum\",\n",
    "                \"weth\": \"weth\",\n",
    "                \"usdc\": \"usd-coin\",\n",
    "                \"usdt\": \"tether\",\n",
    "                \"bnb\": \"binancecoin\",\n",
    "                \"matic\": \"polygon\"\n",
    "            }\n",
    "            cg_id = mapping.get(symbol)\n",
    "\n",
    "            if not cg_id and token_address:\n",
    "                cached_cgid = self.address_cache.get(token_address.lower())\n",
    "                if cached_cgid:\n",
    "                    cg_id = cached_cgid\n",
    "\n",
    "            if not cg_id and token_address:\n",
    "                try:\n",
    "                    url = f\"https://api.coingecko.com/api/v3/coins/{blockchain}/contract/{token_address}\"\n",
    "                    r = requests.get(url)\n",
    "                    if r.status_code == 200:\n",
    "                        data = r.json()\n",
    "                        cg_id = data.get(\"id\")\n",
    "                        if cg_id and self.use_cache:\n",
    "                            self.address_cache.set(token_address.lower(), cg_id)\n",
    "                except Exception as e:\n",
    "                    print(f\"Contract lookup failed for {token_address}: {e}\")\n",
    "\n",
    "            if not cg_id:\n",
    "                return None\n",
    "\n",
    "            url = f\"https://api.coingecko.com/api/v3/coins/{cg_id}/history\"\n",
    "            params = {\"date\": datetime.strptime(date_str, \"%Y-%m-%d\").strftime(\"%d-%m-%Y\")}\n",
    "            r = requests.get(url, params=params)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                price = data.get(\"market_data\", {}).get(\"current_price\", {}).get(\"usd\")\n",
    "                if price and self.use_cache:\n",
    "                    self.price_cache.set(cache_key, price)\n",
    "                return price\n",
    "        except Exception as e:\n",
    "            print(f\"Price fetch error for {symbol} / {token_address}: {e}\")\n",
    "            return None\n",
    "    # -------------------------------\n",
    "    # GAS COSTS (from gas.fees table)\n",
    "    # -------------------------------\n",
    "    def get_gas_costs_for_wallet(self, wallet: str, max_per_chain: int = 50) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch gas fees for a given wallet across supported chains.\n",
    "        Returns DataFrame with tx_hash, gas_used, fee in USD, etc.\n",
    "        \"\"\"\n",
    "        all_gas = []\n",
    "        for chain_name, chain_id in self.chains.items():\n",
    "            try:\n",
    "                url = f\"{self.base_url}/{wallet}/transaction\"\n",
    "                params = {\"chain\": chain_id, \"limit\": max_per_chain}\n",
    "                response = requests.get(url, headers=self.headers, params=params)\n",
    "                if response.status_code != 200:\n",
    "                    continue\n",
    "\n",
    "                txs = response.json().get(\"result\", [])\n",
    "                for tx in txs:\n",
    "                    try:\n",
    "                        fee_usd = float(tx.get(\"gas_price\", 0)) * float(tx.get(\"receipt_gas_used\", 0)) / 1e18 * float(tx.get(\"usd_price\", 0))\n",
    "                        enriched = {\n",
    "                            \"wallet\": wallet,\n",
    "                            \"blockchain\": chain_name,\n",
    "                            \"tx_hash\": tx.get(\"hash\"),\n",
    "                            \"block_time\": tx.get(\"block_timestamp\"),\n",
    "                            \"gas_used\": tx.get(\"receipt_gas_used\"),\n",
    "                            \"gas_price\": tx.get(\"gas_price\"),\n",
    "                            \"gas_fee_usd\": fee_usd,\n",
    "                        }\n",
    "                        all_gas.append(enriched)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Gas enrich error: {e}\")\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                print(f\"Gas fetch error: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not all_gas:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(all_gas)\n",
    "        df['block_time'] = pd.to_datetime(df['block_time'])\n",
    "        return df.sort_values(\"block_time\").reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Runner\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    API_KEY = os.getenv(\"MORALIS_API_KEY\")\n",
    "\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"‚ö†Ô∏è Please add MORALIS_API_KEY to your .env file!\")\n",
    "\n",
    "    wallet_address = \"0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\"  # replace with user input\n",
    "    analyzer = ExtendedMoralisAnalyzer(API_KEY)\n",
    "\n",
    "    df = analyzer.get_detailed_data_for_wallet(wallet_address, max_per_chain=30)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"No transactions found.\")\n",
    "    else:\n",
    "        print(df.head(20))\n",
    "        print(\"\\nSummary USD values:\")\n",
    "        print(df.groupby(\"transaction_type\")[\"usd_value\"].sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WalletPnL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
